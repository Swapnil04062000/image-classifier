{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create a random image with shape (32, 32, 3)\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Create a random image with shape (32, 32, 3)\n",
    "image_array = np.random.rand(32, 32, 3) * 255\n",
    "image = Image.fromarray(image_array.astype('uint8'))\n",
    "\n",
    "# Save the image\n",
    "image.save(\"data/sample_image.jpg\")\n",
    "print(\"Sample image saved as data/sample_image.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image saved as data/sample_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(_, _), (test_images, _) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Get the first test image and normalize it to [0, 255]\n",
    "image_array = (test_images[0]).astype('uint8')\n",
    "\n",
    "# Convert to an image and save\n",
    "image = Image.fromarray(image_array)\n",
    "image.save(\"data/sample_image.jpg\")\n",
    "print(\"Sample image saved as data/sample_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to test_data.json\n"
     ]
    }
   ],
   "source": [
    "from scripts.preprocess import preprocess_image\n",
    "# from preprocess import preprocess_image\n",
    "import json\n",
    "\n",
    "# Preprocess the sample image\n",
    "image_path = \"data/sample_image.jpg\"  # Path to your sample image\n",
    "preprocessed_data = preprocess_image(image_path)\n",
    "\n",
    "# Save preprocessed data as JSON\n",
    "with open(\"test_data.json\", \"w\") as f:\n",
    "    json.dump({\"instances\": preprocessed_data.tolist()}, f)\n",
    "\n",
    "print(\"Preprocessed data saved to test_data.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: class_1\n",
      "Prediction probability: 0.737392128\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# Define the endpoint for the model\n",
    "url = \"http://localhost:8501/v1/models/image_classifier:predict\"\n",
    "\n",
    "# Class labels (replace this with your actual class labels)\n",
    "class_labels = [\"class_1\", \"class_2\", \"class_3\", \"class_4\", \"class_5\", \"class_6\", \"class_7\", \"class_8\", \"class_9\", \"class_10\"]\n",
    "\n",
    "# Load and preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((224, 224))  # Assuming your model expects 224x224 input size\n",
    "    img = np.array(img) / 255.0  # Normalize the image\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img.tolist()  # Convert to list for JSON serialization\n",
    "\n",
    "# Make a prediction\n",
    "def get_prediction(image_path):\n",
    "    data = json.dumps({\"instances\": preprocess_image(image_path)})\n",
    "    \n",
    "    # Send the request to the TensorFlow Serving model\n",
    "    response = requests.post(url, data=data, headers={\"content-type\": \"application/json\"})\n",
    "    \n",
    "    # Get the predicted probabilities from the response\n",
    "    predictions = response.json()[\"predictions\"][0]\n",
    "    \n",
    "    # Find the index of the class with the highest probability\n",
    "    predicted_class_index = np.argmax(predictions)\n",
    "    predicted_class = class_labels[predicted_class_index]\n",
    "    predicted_probability = predictions[predicted_class_index]\n",
    "    \n",
    "    # Return the predicted class and probability\n",
    "    return predicted_class, predicted_probability\n",
    "\n",
    "# Example usage\n",
    "image_path = \"data/sample_image.jpg\"  # Replace with your image path\n",
    "predicted_class, predicted_probability = get_prediction(image_path)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Prediction probability: {predicted_probability}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_file_path):\n",
    "    with open(label_file_path, \"r\") as file:\n",
    "        labels = file.readlines()\n",
    "    return [label.strip() for label in labels]\n",
    "\n",
    "# Load your actual class labels\n",
    "class_labels = load_labels(\"labels.txt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00141992338, 0.000366750872, 0.0412123948, 0.204308644, 0.0535725653, 0.380493104, 0.288085639, 0.00339526217, 0.00187686924, 0.0252688359]\n",
      "5\n",
      "dog\n",
      "Predicted class: dog\n",
      "Prediction probability: 0.380493104\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "from scripts.preprocess import preprocess_image\n",
    "\n",
    "# Define the endpoint for the model\n",
    "url = \"http://localhost:8501/v1/models/image_classifier:predict\"\n",
    "\n",
    "# Load class labels from a file (e.g., 'labels.txt')\n",
    "def load_labels(label_file_path):\n",
    "    with open(label_file_path, \"r\") as file:\n",
    "        labels = file.readlines()\n",
    "    return [label.strip() for label in labels]\n",
    "\n",
    "# Load your actual class labels\n",
    "class_labels = load_labels(\"labels.txt\")  # Replace with the correct path to your label file\n",
    "\n",
    "# Load and preprocess the image\n",
    "# def preprocess_image(image_path):\n",
    "#     img = Image.open(image_path)\n",
    "#     img = img.resize((224, 224))  # Assuming your model expects 224x224 input size\n",
    "#     img = np.array(img) / 255.0  # Normalize the image\n",
    "#     img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "#     return img.tolist()  # Convert to list for JSON serialization\n",
    "\n",
    "\n",
    "# Make a prediction\n",
    "def get_prediction(image_path):\n",
    "    image_data =  preprocess_image(image_path)\n",
    "    \n",
    "    # Send the request to the TensorFlow Serving model\n",
    "    # response = requests.post(url, data=data, headers={\"content-type\": \"application/json\"})\n",
    "    response = requests.post(url, json={\"instances\": image_data.tolist()})\n",
    "    response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "   \n",
    "    # Get the predicted probabilities from the response\n",
    "    predictions = response.json()['predictions'][0]\n",
    "    print(predictions)\n",
    "    # print(predictions['predictions'][0])\n",
    "    \n",
    "    # Find the index of the class with the highest probability\n",
    "    predicted_class_index = np.argmax(predictions)\n",
    "    predicted_class = class_labels[predicted_class_index]\n",
    "    predicted_probability = predictions[predicted_class_index]\n",
    "    \n",
    "    # Return the predicted class and probability\n",
    "    return predicted_class, predicted_probability\n",
    "\n",
    "# Example usage\n",
    "image_path = \"data/sample_image2.jpg\"  # Replace with your image path\n",
    "predicted_class, predicted_probability = get_prediction(image_path)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Prediction probability: {predicted_probability}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(class_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
